# Title slide
## Content

AI-Coding

## Instructions:

(this slide has no headine)

# About me

## Content
Fabian Wesner
CTO & Entrepreneur

Career:
- Solopreneur & AI-Coding Coach
- Tech Co-Founder of Spryker and ROQ
- CTO of Rocket Internet and Project A

https://www.linkedin.com/in/fabian-wesner/

# Today's Agenda

## Content:

(1) Short presentation to set the scenes

(2) Hands-on workshop.

We'll build a full project together. You'll lean how I do it, so you can take inspiration.

(Ongoing): Q&A

I am here to answer all your questions about using AI-coding for your daily work. So don't hesitate to ask me at any time,




# Evolution

## Content (drafted)

- Developer writes code (1x)
- Developer writes code with AI (1,3x) - Tab-completions / In-context editing
- AI writes code with developer (10x) - Coding Agents

## Instructions:

Make it look stunning!!!

# Question 1

## Content

Who of you have experience with
(A) Cursor
(B) Claude Code
(C) Other?

## Instructions

Use the "Who of you have experience with" as headline, not "Question 1"

Improve my copy

None of them is highlighted. But when I use up/down arrows, I can set a highlight-cursor. When I press "SPACE" then I can count (show nicely with a Magic component). Rember the counts in localStorage, so they are not lost for this session.

# Question2

## Content

Who of you have experience with
(A) MCPs
(B) Sub-Agents
(C) Planning-Mode

## Instructions

Same as above


# Agent theory

## Instructions

Visually explain how Claude Code works (basics)
Re-Act / Orchestrator



# Starting is very easy!

## Instructions

Show a basic prompt example, like adding a button

# But doing it "right" is hard.

## Content

=> The AI will fill specification-gaps.
=> Leads to frustration (AI isn't doing what I want....)

## Instructions



(show the open specifications gap of the button, like what color, size, action, double-click ....)


(Optimize my copy and make it visually stunning)

=================== STOP===================


# Ways how to use it (feel free to improve the copy)

(1) Prompt very specfic commands 
"Do this, do that" (<- often called "vibe coding")
+ Good for fine-tuning (ideally with visual confirmation)
- Bad for building complex features (leds to brain rot)

(2) Brainstorm with AI
Do a full brainstorming session with the coding agent. Result is a very detailed "prompt" with hundrets or thousands of lines. 

We'll do both today!

# AI-Coding Checklist

(checkmark) Brainstorm with AI 


(This checklist will be shown multiple times, and we'll add items)


============================== NOT PREPARED ==============================


# How to ensure quality?

Quality?
- Architecture stays consistent
- Code conventions are obeyed
- Existing libraries are used
- Code is tests
- Features are complete and correct

# Jobs of the developer

Before (simplified)
* Technical specifications
* Programming
* (Unit) testing
* Validation of results

With AI Coding Agent
* Technical specifications (80%)
* Validation of results (10%)
* Perfectionizing the setup for the Coding Agent (5%)
* Coding (5%)



Mental model. Architecture clean, code conventions

Testing
Patterns: Unit, browser, try, database


Agent theory

Context management with sub agents

Accesscto docs

Claude Code vs Cursor

Cc with other llms

MCPs

Agent techniques (last post)

Commands

Roadmap
Practice all types of AI coding


Challenge
Knowledge sharing
Code reviews
Peoduct vs Engineering vs QA

Documentation building

Run without approvals
- directly (risky, powerful)
- isolated (recommendet)

Typical concerns
Only Greenfield
Developers do more than coding

To make AI work you need
1. Complete technical specifications (to avoid filling the gap)
2. Knowledge about you conversations,c architecture, features, schema, terms
3. Access to documentation of your frameworks
4. Ability to test
5. Automated reviews (specs fully implemented, architecture in place?)



Why hard?
Even small features, c require a lot of specs (or AI will fill the gaps - random results)
Code conventions or architecture might be broken
Mental model is gone
It might do nonsense (it might delete broken tests instead of fixing)

What helps:
Detailed instructions
Let AI test it
Let AI do a critical review
Validate yourself (time consuming)

Increasing productivity means to Systematically eliminate all human work and only do what AI cannot (Giving the intent)

When something for wrong, fix it and make sure it never happens and again.

When AI makes a "mistake" then it's
95% missing clear instructions (can be fixed)
5% Non deterministic behavior (can be checked)
Percentage values are based on my experience

Developer is still fully responsible for its work
Review everything
Enforce best practices, set architecture guardrails and code conventions.
Don't push code, you don't understand

How to make the agent do what youneer?
Full spec
Guardrails / Reviews
Tools to enable it to try it out
Final review by human

- Very easy to start with, but also very easy to fail